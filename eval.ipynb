{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34478f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca6fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2dbcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d08dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_all_ranked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6234d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.df[\"text\"] = self.df[\"ranked-sentences\"].progress_apply(lambda x:\" \".join(eval(x)[:10]))\n",
    "        #self.df[\"label\"] = self.df[\"decision\"].progress_apply(lambda x:1 if x==\"granted\" else 0)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        model_input = self.df['text'][idx]\n",
    "        encoded_sent = self.tokenizer.encode_plus(\n",
    "            text=model_input,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation=True\n",
    "            )\n",
    "\n",
    "        input_ids = encoded_sent.get('input_ids')\n",
    "        attention_mask = encoded_sent.get('attention_mask')\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "        label = torch.tensor(self.df['label'][idx])\n",
    "\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e0cb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16a0ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35400/35400 [00:01<00:00, 25503.27it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = LegalDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66dad253",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = evaluate.load(\"accuracy\")\n",
    "metric2 = evaluate.load(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric2.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    return {'accuracy': accuracy[\"accuracy\"], 'f1-score': f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d469e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4425' max='4425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4425/4425 13:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8779400587081909, 'eval_model_preparation_time': 0.0076, 'eval_accuracy': 0.8450282485875706, 'eval_f1-score': 0.8330939009867592, 'eval_runtime': 804.789, 'eval_samples_per_second': 43.987, 'eval_steps_per_second': 5.498}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# 1. Load the trained model from the \"model\" directory\n",
    "# Ensure the \"model\" folder from the training notebook is in the same directory as this notebook\n",
    "model_path = \"./model\" \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# 2. Define TrainingArguments for evaluation (minimal configuration needed)\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=\"eval_output\",\n",
    "    per_device_eval_batch_size=8,  # Match the batch size used in training or adjust for memory\n",
    "    do_train=False,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "# 3. Initialize the Trainer\n",
    "# We use the loaded model, the test dataset you created, and the metrics function\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=eval_args,\n",
    "    eval_dataset=test_dataset,     # Using the test_dataset defined in your previous cells\n",
    "    compute_metrics=compute_metrics # Using the compute_metrics defined in your previous cells\n",
    ")\n",
    "\n",
    "# 4. Run Evaluation\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bail (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
