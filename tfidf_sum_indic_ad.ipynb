{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1489057c-0e87-47e8-97f7-0a630d6eadf9",
      "metadata": {
        "id": "1489057c-0e87-47e8-97f7-0a630d6eadf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d-7XBuJLEbb",
      "metadata": {
        "id": "2d-7XBuJLEbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): Traceback (most recent call last):\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/bin/hf\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/cli/hf.py\", line 59, in main\n",
            "    service.run()\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/cli/auth.py\", line 126, in run\n",
            "    login(\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 124, in login\n",
            "    interpreter_login(new_session=new_session)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 281, in interpreter_login\n",
            "    token = getpass(\"Enter your token (input will not be visible): \")\n",
            "  File \"/home/amlan/snap/code/215/.local/share/uv/python/cpython-3.10.18-linux-x86_64-gnu/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
            "    passwd = _raw_input(prompt, stream, input=input)\n",
            "  File \"/home/amlan/snap/code/215/.local/share/uv/python/cpython-3.10.18-linux-x86_64-gnu/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
            "    line = input.readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!hf auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1778e89-05f3-4fbd-a4ff-5b5f19e36ea8",
      "metadata": {
        "id": "a1778e89-05f3-4fbd-a4ff-5b5f19e36ea8"
      },
      "outputs": [],
      "source": [
        "from transformers import AlbertTokenizer\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b185d897-cde9-4e05-99ba-5a19efd91597",
      "metadata": {
        "id": "b185d897-cde9-4e05-99ba-5a19efd91597"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\"ai4bharat/indic-bert\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "14e5f6a6-251f-486c-9991-12a04862a442",
      "metadata": {
        "id": "14e5f6a6-251f-486c-9991-12a04862a442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b943277e-f9a4-424c-aaa3-74332f61b725",
      "metadata": {
        "id": "b943277e-f9a4-424c-aaa3-74332f61b725"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"train_all_ranked.csv\")\n",
        "test_df = pd.read_csv(\"dev_all_ranked.csv\")\n",
        "#train_df = train_df.head(500)\n",
        "#test_df = test_df.head(500)\n",
        "hp_train_df = train_df.sample(frac = 0.1, random_state=42).reset_index()\n",
        "hp_test_df = test_df.sample(frac = 0.1, random_state=42).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "48b147cc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    {'facts-and-arguments': ['अग्रिम जमानत प्रार्थ...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(1)['text']\n",
        "#test_df = test_df.head(500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d1187d44-7724-4bbc-b33b-dcc002de74bd",
      "metadata": {
        "id": "d1187d44-7724-4bbc-b33b-dcc002de74bd"
      },
      "outputs": [],
      "source": [
        "class LegalDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.df[\"text\"] = self.df[\"ranked-sentences\"].progress_apply(lambda x:\" \".join(eval(x)[:10]))\n",
        "        #self.df[\"label\"] = self.df[\"decision\"].progress_apply(lambda x:1 if x==\"granted\" else 0)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        model_input = self.df['text'][idx]\n",
        "        encoded_sent = self.tokenizer.encode_plus(\n",
        "            text=model_input,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            truncation=True\n",
        "            )\n",
        "\n",
        "        input_ids = encoded_sent.get('input_ids')\n",
        "        attention_mask = encoded_sent.get('attention_mask')\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "        label = torch.tensor(self.df['label'][idx])\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "57773094-f2dd-4aae-9eb9-ffb3837f37de",
      "metadata": {
        "id": "57773094-f2dd-4aae-9eb9-ffb3837f37de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/123742 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 123742/123742 [00:09<00:00, 12660.57it/s]\n",
            "100%|██████████| 17707/17707 [00:00<00:00, 31838.64it/s]\n",
            "100%|██████████| 12374/12374 [00:00<00:00, 36785.65it/s]\n",
            "100%|██████████| 1771/1771 [00:00<00:00, 33772.74it/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = LegalDataset(train_df, tokenizer)\n",
        "test_dataset = LegalDataset(test_df, tokenizer)\n",
        "hp_train_dataset = LegalDataset(hp_train_df, tokenizer)\n",
        "hp_test_dataset = LegalDataset(hp_test_df, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "167dbcbc-389f-45d4-80e0-b765e1dfac19",
      "metadata": {
        "id": "167dbcbc-389f-45d4-80e0-b765e1dfac19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading builder script: 4.20kB [00:00, 3.62MB/s]\n",
            "Downloading builder script: 6.79kB [00:00, 4.45MB/s]\n"
          ]
        }
      ],
      "source": [
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6c42716a-745e-4727-8e01-ea363abedea1",
      "metadata": {
        "id": "6c42716a-745e-4727-8e01-ea363abedea1"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = metric1.compute(predictions=predictions, references=labels)\n",
        "    f1 = metric2.compute(predictions=predictions, references=labels, average=\"micro\")\n",
        "    return {'accuracy': accuracy[\"accuracy\"], 'f1-score': f1[\"f1\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "51569c0c-6377-403e-b2c9-ba33e8290bd9",
      "metadata": {
        "id": "51569c0c-6377-403e-b2c9-ba33e8290bd9"
      },
      "outputs": [],
      "source": [
        "def my_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"weight_decay\":trial.suggest_float(\"weight_decay\", 0.005, 0.05),\n",
        "        \"adam_beta1\":trial.suggest_float(\"adam_beta1\", 0.75, 0.95),\n",
        "        \"adam_beta2\":trial.suggest_float(\"adam_beta2\", 0.99, 0.9999),\n",
        "        \"adam_epsilon\":trial.suggest_float(\"adam_epsilon\", 1e-9, 1e-7, log=True)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "46cf81c2-18fe-4bde-b2c1-bb7b7a571c7a",
      "metadata": {
        "id": "46cf81c2-18fe-4bde-b2c1-bb7b7a571c7a"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='htf2_results',          # output directory\n",
        "    num_train_epochs=5,            # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,              # strength of weight decay\n",
        "    logging_dir='htf2_logs',           # directory for storing logs\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=250,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit = 1,\n",
        "    learning_rate = 0.00001,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model =\"eval_f1-score\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "73102706-55c1-4c83-a6e1-34870dbfc1c9",
      "metadata": {
        "id": "73102706-55c1-4c83-a6e1-34870dbfc1c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_30849/2587673528.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model_init=model_init,                        # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=hp_train_dataset,         # training dataset\n",
        "    eval_dataset=hp_test_dataset,           # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "861aa998-6334-498a-b2e8-f12a58039340",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "861aa998-6334-498a-b2e8-f12a58039340",
        "outputId": "74963e56-3cfc-4032-9791-701aef035d18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-15 12:12:52,738] A new study created in memory with name: no-name-12b64b59-26db-492a-af9e-3fb6c1e68041\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7735' max='7735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7735/7735 1:11:55, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.675900</td>\n",
              "      <td>0.660075</td>\n",
              "      <td>0.627894</td>\n",
              "      <td>0.627894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.675400</td>\n",
              "      <td>0.659552</td>\n",
              "      <td>0.627894</td>\n",
              "      <td>0.627894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.593200</td>\n",
              "      <td>0.588971</td>\n",
              "      <td>0.696217</td>\n",
              "      <td>0.696217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.545100</td>\n",
              "      <td>0.528042</td>\n",
              "      <td>0.748165</td>\n",
              "      <td>0.748165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.498100</td>\n",
              "      <td>0.516058</td>\n",
              "      <td>0.757199</td>\n",
              "      <td>0.757199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-15 13:24:51,752] Trial 0 finished with value: 1.5143986448334275 and parameters: {'learning_rate': 4.643981250325776e-05, 'weight_decay': 0.03809725020772307, 'adam_beta1': 0.8178722055669438, 'adam_beta2': 0.9970260800287583, 'adam_epsilon': 7.458155533648117e-09}. Best is trial 0 with value: 1.5143986448334275.\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7735' max='7735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7735/7735 1:22:41, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.630900</td>\n",
              "      <td>0.629781</td>\n",
              "      <td>0.645963</td>\n",
              "      <td>0.645963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.603100</td>\n",
              "      <td>0.589940</td>\n",
              "      <td>0.669113</td>\n",
              "      <td>0.669113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.560965</td>\n",
              "      <td>0.712592</td>\n",
              "      <td>0.712592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.541000</td>\n",
              "      <td>0.557136</td>\n",
              "      <td>0.710898</td>\n",
              "      <td>0.710898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.523300</td>\n",
              "      <td>0.559705</td>\n",
              "      <td>0.715415</td>\n",
              "      <td>0.715415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-15 14:47:35,658] Trial 1 finished with value: 1.4308300395256917 and parameters: {'learning_rate': 3.366363048523265e-06, 'weight_decay': 0.013682001577772673, 'adam_beta1': 0.7667682000952083, 'adam_beta2': 0.9947310374831695, 'adam_epsilon': 1.4881366673767326e-08}. Best is trial 0 with value: 1.5143986448334275.\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6990' max='7735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6990/7735 1:05:30 < 06:59, 1.78 it/s, Epoch 4.52/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.631600</td>\n",
              "      <td>0.609807</td>\n",
              "      <td>0.661773</td>\n",
              "      <td>0.661773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.595100</td>\n",
              "      <td>0.596238</td>\n",
              "      <td>0.676454</td>\n",
              "      <td>0.676454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.550200</td>\n",
              "      <td>0.577847</td>\n",
              "      <td>0.694523</td>\n",
              "      <td>0.694523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.557300</td>\n",
              "      <td>0.571915</td>\n",
              "      <td>0.702428</td>\n",
              "      <td>0.702428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-12-15 15:53:08,086] Trial 2 failed with parameters: {'learning_rate': 2.663993729992551e-06, 'weight_decay': 0.03363998169624114, 'adam_beta1': 0.813870886698232, 'adam_beta2': 0.992291282263385, 'adam_epsilon': 7.216750511119966e-09} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 277, in _objective\n",
            "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2325, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/home/amlan/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2679, in _inner_training_loop\n",
            "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
            "KeyboardInterrupt\n",
            "[W 2025-12-15 15:53:08,087] Trial 2 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mhp_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_hp_space\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/trainer.py:3767\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3764\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m hp_name\n\u001b[1;32m   3765\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_objective \u001b[38;5;241m=\u001b[39m default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[0;32m-> 3767\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_search_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/hyperparameter_search.py:72\u001b[0m, in \u001b[0;36mOptunaBackend.run\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, n_trials: \u001b[38;5;28mint\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_hp_search_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:295\u001b[0m, in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m directions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m direction\n\u001b[1;32m    294\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection, directions\u001b[38;5;241m=\u001b[39mdirections, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 295\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    297\u001b[0m     best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    261\u001b[0m ):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:277\u001b[0m, in \u001b[0;36mrun_hp_search_optuna.<locals>._objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    275\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/legal/joshi/bail/.venv/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_run = trainer.hyperparameter_search(n_trials=10,direction=\"maximize\",hp_space=my_hp_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49be5278-a464-487d-b15d-04bbd6b0c927",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49be5278-a464-487d-b15d-04bbd6b0c927",
        "outputId": "b86375a4-1da9-41a6-8d44-edb5a146c083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best HyperParameters\n"
          ]
        }
      ],
      "source": [
        "print(\"Best HyperParameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f33eaac8-878d-49d6-b75f-be7666736f67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "f33eaac8-878d-49d6-b75f-be7666736f67",
        "outputId": "3cfe037b-7e66-48c0-85af-9567da94720d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_run' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_run\u001b[49m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_run' is not defined"
          ]
        }
      ],
      "source": [
        "print(best_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d2bacb-b8b3-4ade-ad31-3df04cfff6b2",
      "metadata": {
        "id": "52d2bacb-b8b3-4ade-ad31-3df04cfff6b2"
      },
      "outputs": [],
      "source": [
        "del trainer\n",
        "del training_args\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d1868ea-2697-49e5-95ec-87038d6e4897",
      "metadata": {
        "id": "7d1868ea-2697-49e5-95ec-87038d6e4897"
      },
      "outputs": [],
      "source": [
        "print(\"Starting Training...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016961c4-a64a-41a2-85b5-bc97d968ca2e",
      "metadata": {
        "id": "016961c4-a64a-41a2-85b5-bc97d968ca2e"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/scratch/username/tf2_results',          # output directory\n",
        "    num_train_epochs=15,            # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,              # strength of weight decay\n",
        "    logging_dir='/scratch/username/tf2_logs',           # directory for storing logs\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_steps=250,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit = 1,\n",
        "    learning_rate = 0.00001,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model =\"eval_f1-score\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb13ccc5-14c5-4d51-ac66-1428260e6d02",
      "metadata": {
        "id": "bb13ccc5-14c5-4d51-ac66-1428260e6d02"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model_init=model_init,                        # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d9c54ab-3406-4d09-9742-ff1a95e45423",
      "metadata": {
        "id": "2d9c54ab-3406-4d09-9742-ff1a95e45423"
      },
      "outputs": [],
      "source": [
        "for n, v in best_run.hyperparameters.items():\n",
        "    setattr(trainer.args, n, v)\n",
        "print(trainer.args)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69b3b80-7013-4e1d-ae8f-54b10a68918a",
      "metadata": {
        "id": "c69b3b80-7013-4e1d-ae8f-54b10a68918a"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/home2/username/legal-tech/tfidf_sum+indic-ad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bc1ada-9468-474c-b9d3-190ea806fabf",
      "metadata": {
        "id": "b5bc1ada-9468-474c-b9d3-190ea806fabf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bail (3.10.18)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
